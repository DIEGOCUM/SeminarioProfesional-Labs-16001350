{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "16001350-Lab5RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMYLJM7IbcsiLtOFpfWwccL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIEGOCUM/SeminarioProfesional-Labs-16001350/blob/master/16001350_Lab5RNN_WithoutNormalizingAndCuDNNLSTM_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1fWnx3aKEqk",
        "colab_type": "text"
      },
      "source": [
        "#Importar TensorFlow\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWNHwf6pCBr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RNN Order of dart has weigth and order \n",
        "# Tokenizer data, some people made a neural network . a neural network made some people\n",
        "#  sequential data, the cell pass to the next layer to the next recurrent \n",
        "# also down to the next node to de specific recurrent layer, but its learning by the last one\n",
        "# cell has \n",
        "  # x  -> forget Gate (what we wanna forget of the previos gate) -> add What (what i wanna add) -> what output to next node \n",
        "  # lstm long shor term memory\n",
        "  # output layer need be a dense layer (before output layer)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xcmsv7rHKNUL",
        "colab_type": "text"
      },
      "source": [
        "#Import keras mis\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_QYSFWTC_2t",
        "colab_type": "code",
        "outputId": "bfa27c42-6f62-4a4d-9cb5-562697e4047f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape)\n",
        "print(x_train[0].shape) \n",
        "# 60000 images of 28x28\n",
        "# this is in sequences, what is 28x28? (28 rows of 28 columns)\n",
        "# not normalizing the data\n",
        "# x_train = x_train/255.0\n",
        "# x_test = x_test/255.0\n",
        "# y_train = y_train/255.0\n",
        "# y_test = y_test/255.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtUasgxvKUJ9",
        "colab_type": "text"
      },
      "source": [
        "#Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQKX0ZkpDn3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "#how many cells of lstm we wanna have (128)\n",
        "#Rectified Linear Unit (ReLU) \n",
        "# Do we wanna to this layer to output sequences or return something flat (dense layer need sequences)\n",
        "model.add(LSTM(128, input_shape=(x_train.shape[1:]), activation='relu', return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "# 128 layer\n",
        "model.add(LSTM(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "# 32 layer\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "# 32 layer\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "# Large steps of decay( small steps)\n",
        "opt = tf.keras.optimizers.Adam(lr=1e-3, decay=1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bSpv98tK4CY",
        "colab_type": "text"
      },
      "source": [
        "# Entrenando la data Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LWygayDGq3f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e4080cf7-7669-41a7-a008-56474d34a697"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=3, validation_data=(x_test, y_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 259s 4ms/sample - loss: 29.5956 - acc: 0.1113 - val_loss: 2.3060 - val_acc: 0.1131\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 257s 4ms/sample - loss: 2.3733 - acc: 0.1122 - val_loss: 2.3011 - val_acc: 0.1135\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 258s 4ms/sample - loss: 2.3119 - acc: 0.1124 - val_loss: 2.3011 - val_acc: 0.1135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbab3f4b438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWTYYQryLLnP",
        "colab_type": "text"
      },
      "source": [
        "# Construimos el Modelo y configuramos el optimizador y el loss function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-TA8Va5EMfp",
        "colab_type": "code",
        "outputId": "1ee92681-b5cf-434a-bdc3-0669e5f75ece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "  keras.layers.Embedding(encoder.vocab_size, 16),\n",
        "  keras.layers.GlobalAveragePooling1D(),\n",
        "  keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 16)          130960    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 130,977\n",
            "Trainable params: 130,977\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeLW5vVBLaAd",
        "colab_type": "text"
      },
      "source": [
        "# Entrenamos el modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBKXFqa8Gial",
        "colab_type": "code",
        "outputId": "10d61a1b-0047-46a9-c09d-73c57324b69f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "history = model.fit(train_batches,\n",
        "                    epochs=10,\n",
        "                    validation_data=test_batches,\n",
        "                    validation_steps=30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on None steps, validate on 30 steps\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.6827 - acc: 0.6134 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.6252 - acc: 0.7499 - val_loss: 0.5984 - val_acc: 0.7792\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.5461 - acc: 0.8030 - val_loss: 0.5320 - val_acc: 0.8115\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4773 - acc: 0.8369 - val_loss: 0.4782 - val_acc: 0.8146\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4243 - acc: 0.8612 - val_loss: 0.4368 - val_acc: 0.8594\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 10s 12ms/step - loss: 0.3842 - acc: 0.8756 - val_loss: 0.4047 - val_acc: 0.8646\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 10s 12ms/step - loss: 0.3522 - acc: 0.8856 - val_loss: 0.3788 - val_acc: 0.8667\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 10s 12ms/step - loss: 0.3252 - acc: 0.8922 - val_loss: 0.3592 - val_acc: 0.8750\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3046 - acc: 0.8985 - val_loss: 0.3432 - val_acc: 0.8792\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2885 - acc: 0.9042 - val_loss: 0.3305 - val_acc: 0.8792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D55chlShLd1n",
        "colab_type": "text"
      },
      "source": [
        "# Evaluamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RClWGEwJ3dY",
        "colab_type": "code",
        "outputId": "49f1494c-5b38-42b2-ec0f-0d7c617b8cbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "loss, accuracy = model.evaluate(test_batches)\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    782/Unknown - 7s 9ms/step - loss: 0.3332 - acc: 0.8762Loss:  0.3331779088643963\n",
            "Accuracy:  0.8762\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}