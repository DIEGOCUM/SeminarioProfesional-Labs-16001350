{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "16001350-Lab3TextClassification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNkJNqQAq+9uQx3J5bhpeLE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIEGOCUM/SeminarioProfesional-Labs-16001350/blob/master/16001350_Lab3TextClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1fWnx3aKEqk",
        "colab_type": "text"
      },
      "source": [
        "#Importar TensorFlow\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWNHwf6pCBr9",
        "colab_type": "code",
        "outputId": "d54faed0-70d1-4644-c9fc-d0c8cb2e32b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "!pip install -q tensorflow-datasets\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xcmsv7rHKNUL",
        "colab_type": "text"
      },
      "source": [
        "#IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_QYSFWTC_2t",
        "colab_type": "code",
        "outputId": "98e38088-4942-4d8a-8d29-c1f3a12e06a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "(train_data, test_data), info = tfds.load(\n",
        "    # Use the version pre-encoded with an ~8k vocabulary.\n",
        "    'imdb_reviews/subwords8k', \n",
        "    # Return the train/test datasets as a tuple.\n",
        "    split = (tfds.Split.TRAIN, tfds.Split.TEST),\n",
        "    # Return (example, label) pairs from the dataset (instead of a dictionary).\n",
        "    as_supervised=True,\n",
        "    # Also return the `info` structure. \n",
        "    with_info=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset imdb_reviews (80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/subwords8k/0.1.0...\u001b[0m\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_datasets/core/file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtUasgxvKUJ9",
        "colab_type": "text"
      },
      "source": [
        "#Encode \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQKX0ZkpDn3j",
        "colab_type": "code",
        "outputId": "6aaff326-c973-4a7d-d2be-4d533eb3ce5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "encoder = info.features['text'].encoder\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 8185\n",
            "Encoded string is [7998, 2045, 4568, 222, 2091, 7961, 6213, 665, 7975]\n",
            "The original string: \"Ejemplo del encode.\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bSpv98tK4CY",
        "colab_type": "text"
      },
      "source": [
        "# Entrenando la data Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LWygayDGq3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 1000\n",
        "\n",
        "train_batches = (\n",
        "    train_data\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .padded_batch(32, train_data.output_shapes))\n",
        "\n",
        "test_batches = (\n",
        "    test_data\n",
        "    .padded_batch(32, train_data.output_shapes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWTYYQryLLnP",
        "colab_type": "text"
      },
      "source": [
        "# Construimos el Modelo y configuramos el optimizador y el loss function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-TA8Va5EMfp",
        "colab_type": "code",
        "outputId": "1ee92681-b5cf-434a-bdc3-0669e5f75ece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "  keras.layers.Embedding(encoder.vocab_size, 16),\n",
        "  keras.layers.GlobalAveragePooling1D(),\n",
        "  keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 16)          130960    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 130,977\n",
            "Trainable params: 130,977\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeLW5vVBLaAd",
        "colab_type": "text"
      },
      "source": [
        "# Entrenamos el modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBKXFqa8Gial",
        "colab_type": "code",
        "outputId": "10d61a1b-0047-46a9-c09d-73c57324b69f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "history = model.fit(train_batches,\n",
        "                    epochs=10,\n",
        "                    validation_data=test_batches,\n",
        "                    validation_steps=30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on None steps, validate on 30 steps\n",
            "Epoch 1/10\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.6827 - acc: 0.6134 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.6252 - acc: 0.7499 - val_loss: 0.5984 - val_acc: 0.7792\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.5461 - acc: 0.8030 - val_loss: 0.5320 - val_acc: 0.8115\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4773 - acc: 0.8369 - val_loss: 0.4782 - val_acc: 0.8146\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4243 - acc: 0.8612 - val_loss: 0.4368 - val_acc: 0.8594\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 10s 12ms/step - loss: 0.3842 - acc: 0.8756 - val_loss: 0.4047 - val_acc: 0.8646\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 10s 12ms/step - loss: 0.3522 - acc: 0.8856 - val_loss: 0.3788 - val_acc: 0.8667\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 10s 12ms/step - loss: 0.3252 - acc: 0.8922 - val_loss: 0.3592 - val_acc: 0.8750\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3046 - acc: 0.8985 - val_loss: 0.3432 - val_acc: 0.8792\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2885 - acc: 0.9042 - val_loss: 0.3305 - val_acc: 0.8792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D55chlShLd1n",
        "colab_type": "text"
      },
      "source": [
        "# Evaluamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RClWGEwJ3dY",
        "colab_type": "code",
        "outputId": "49f1494c-5b38-42b2-ec0f-0d7c617b8cbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "loss, accuracy = model.evaluate(test_batches)\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    782/Unknown - 7s 9ms/step - loss: 0.3332 - acc: 0.8762Loss:  0.3331779088643963\n",
            "Accuracy:  0.8762\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}