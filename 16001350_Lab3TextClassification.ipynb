{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "16001350-Lab3TextClassification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMZ3hm9rEa63InWcm/o0Ohe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DIEGOCUM/SeminarioProfesional-Labs-16001350/blob/master/16001350_Lab3TextClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1fWnx3aKEqk",
        "colab_type": "text"
      },
      "source": [
        "#Importar TensorFlow, enable eager for tf iteration and import datasets \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWNHwf6pCBr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "# Installa TensorFlow\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "tf.executing_eagerly()\n",
        "\n",
        "!pip install -q tensorflow-datasets\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xcmsv7rHKNUL",
        "colab_type": "text"
      },
      "source": [
        "#Usamos una version de un vocabularios precodificado de IMDB dataset y importamos el data set como tuplas "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_QYSFWTC_2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_data, test_data), info = tfds.load(\n",
        "    'imdb_reviews/subwords8k', \n",
        "    split = (tfds.Split.TRAIN, tfds.Split.TEST),\n",
        "    as_supervised=True,\n",
        "    with_info=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtUasgxvKUJ9",
        "colab_type": "text"
      },
      "source": [
        "#Probamos codificar y decodificar una oracion y una parte del train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQKX0ZkpDn3j",
        "colab_type": "code",
        "outputId": "db0f8d45-f69a-4515-ebb7-1f5b0ff2a643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "encoder = info.features['text'].encoder\n",
        "\n",
        "sample_string = 'Probamos el codificador de palabras.'\n",
        "\n",
        "encoded_string = encoder.encode(sample_string)\n",
        "print ('Codificamos el test {}'.format(encoded_string))\n",
        "\n",
        "original_string = encoder.decode(encoded_string)\n",
        "print ('Mostramos la oracion original: \"{}\"'.format(original_string))\n",
        "\n",
        "\n",
        "assert original_string == sample_string\n",
        "\n",
        "for ts in encoded_string:\n",
        "  print ('{} ----> {}'.format(ts, encoder.decode([ts])))\n",
        "\n",
        "for train_example, train_label in train_data.take(1):\n",
        "  print('Variable codificada  del train example:', train_example[90:100].numpy())\n",
        "  print('Variable decodificada del train example:', encoder.decode(train_example[90:100].numpy()))\n",
        "  print('Label:', train_label.numpy())\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Codificamos el test [6691, 2827, 8, 1121, 4306, 6665, 5608, 7961, 510, 1920, 4870, 453, 7975]\n",
            "Mostramos la oracion original: \"Probamos el codificador de palabras.\"\n",
            "6691 ----> Prob\n",
            "2827 ----> amo\n",
            "8 ----> s \n",
            "1121 ----> el \n",
            "4306 ----> cod\n",
            "6665 ----> ifica\n",
            "5608 ----> dor\n",
            "7961 ---->  \n",
            "510 ----> de \n",
            "1920 ----> pal\n",
            "4870 ----> abr\n",
            "453 ----> as\n",
            "7975 ----> .\n",
            "Variable codificada  del train example: [2836  311    5 5080 1209    3  183  117   35 1187]\n",
            "Variable decodificada del train example: urist and cartoonist. He could be serious \n",
            "Label: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bSpv98tK4CY",
        "colab_type": "text"
      },
      "source": [
        "# Entrenando la data Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LWygayDGq3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 1000\n",
        "\n",
        "train_batches = (\n",
        "    train_data\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .padded_batch(32, train_data.output_shapes))\n",
        "\n",
        "test_batches = (\n",
        "    test_data\n",
        "    .padded_batch(32, train_data.output_shapes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWTYYQryLLnP",
        "colab_type": "text"
      },
      "source": [
        "# Construimos el Modelo y configuramos el optimizador y el loss function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-TA8Va5EMfp",
        "colab_type": "code",
        "outputId": "a040666e-80a6-4861-9330-e7b411ee5729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "  keras.layers.Embedding(encoder.vocab_size, 16),\n",
        "  keras.layers.GlobalAveragePooling1D(),\n",
        "  keras.layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# usamos binary_crossentropy porque trabaja mejor probabilidades"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          130960    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 130,977\n",
            "Trainable params: 130,977\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeLW5vVBLaAd",
        "colab_type": "text"
      },
      "source": [
        "# Entrenamos el modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBKXFqa8Gial",
        "colab_type": "code",
        "outputId": "9ee8f781-2a46-4078-a13e-51af9b1f1d6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        }
      },
      "source": [
        "history = model.fit(train_batches,\n",
        "                    epochs=10,\n",
        "                    validation_data=test_batches,\n",
        "                    validation_steps=30)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 13s 17ms/step - loss: 0.6832 - acc: 0.6111 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.6265 - acc: 0.7494 - val_loss: 0.5991 - val_acc: 0.7833\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.5487 - acc: 0.8005 - val_loss: 0.5340 - val_acc: 0.8146\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.4820 - acc: 0.8354 - val_loss: 0.4808 - val_acc: 0.8417\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 10s 12ms/step - loss: 0.4285 - acc: 0.8592 - val_loss: 0.4385 - val_acc: 0.8490\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3866 - acc: 0.8730 - val_loss: 0.4057 - val_acc: 0.8594\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3538 - acc: 0.8838 - val_loss: 0.3802 - val_acc: 0.8646\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3277 - acc: 0.8911 - val_loss: 0.3602 - val_acc: 0.8729\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3064 - acc: 0.8984 - val_loss: 0.3442 - val_acc: 0.8781\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2887 - acc: 0.9031 - val_loss: 0.3313 - val_acc: 0.8813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D55chlShLd1n",
        "colab_type": "text"
      },
      "source": [
        "# Evaluamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RClWGEwJ3dY",
        "colab_type": "code",
        "outputId": "83d9788a-a6b6-4b0e-efe8-f2e9f3b7b9af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "loss, accuracy = model.evaluate(test_batches)\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3346 - acc: 0.8749\n",
            "Loss:  0.3346203866574313\n",
            "Accuracy:  0.87488\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}